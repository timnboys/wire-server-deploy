---
- name: Setup Minikube Cluster and Configure Nodes
  hosts: deploy_node
  become: yes
  tasks:
  - name: Check DNS A records
    vars:
      dns_records:
        - sftd.{{ target_domain }}
        - nginz-https.{{ target_domain }}
        - nginz-ssl.{{ target_domain }}
        - webapp.{{ target_domain }}
        - assets.{{ target_domain }}
        - teams.{{ target_domain }}
        - account.{{ target_domain }}
    block:
    - name: Resolve the IP address of the inventory hostname
      command: "dig +short {{ inventory_hostname }}"
      register: resolved_ip
      changed_when: false

    - name: Set the resolved IP address as a fact
      set_fact:
        host_ip: "{{ resolved_ip.stdout.strip() }}"

    - name: Resolve DNS A record for {{ item }}
      command: "dig +short {{ item }}"
      register: dns_result
      failed_when: false
      changed_when: false
      with_items: "{{ dns_records }}"

    - name: Log if DNS record does not match the inventory hostname IP
      shell: "echo 'DNS record {{ item.item }} does not match with the inventory hostname IP {{ host_ip }}'"
      when: item.stdout | trim != host_ip
      with_items: "{{ dns_result.results }}"

    when: skip_verify_dns | default(false) == false

  - name: Package installation and configuration
    block:
      - name: apt update
        apt: update_cache=yes force_apt_get=yes

      - name: apt upgrade
        apt: upgrade=dist force_apt_get=yes

      - name: Install dependencies
        apt:
          name:
          # common packages
            - yq
            - aptitude
            - bind9-host
            - debian-goodies
            - dnsutils
            - git
            - dnsmasq
            - less
            - lsof
            - net-tools
            - rsyslog
            - screen
            - sudo
            - vim
            - wget
            - whois
            - telnet
            - python3-lxml
            - apt-transport-https
            - ca-certificates
            - curl
            - software-properties-common
            - bridge-utils
          # team collaboration
            - tmate
            - asciinema
          state: present
          update_cache: yes

      - name: Create /etc/apt/keyrings directory
        file:
          path: /etc/apt/keyrings
          state: directory
          mode: '0755'

      - name: Download Docker GPG key
        get_url:
          url: https://download.docker.com/linux/ubuntu/gpg
          dest: /etc/apt/keyrings/docker.asc
          mode: '0644'

      - name: Add Docker repository to apt sources
        shell: |
          echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo $VERSION_CODENAME) stable" > /etc/apt/sources.list.d/docker.list
        args:
          executable: /bin/bash

      - name: Update apt package index
        apt:
          update_cache: yes

      # fix: static version for docker packages
      - name: Install Docker packages
        apt:
          name:
          - docker-ce={{ docker_ce_version }}
          - docker-ce-cli={{ docker_ce_version }}
          - containerd.io={{ containerd_version }}
          state: present

      - name: Add ubuntu user to the docker group
        user:
          name: "{{ ansible_user }}" # Replace with the username you want to modify
          groups: docker
          append: yes

      - name: Enable and start Docker service
        systemd:
          name: docker
          enabled: yes
          state: started

      - name: Reset SSH connection to apply docker group membership changes
        meta: reset_connection

      # fix: static path for a minikube version
      - name: Install Minikube
        get_url:
          url: "https://github.com/kubernetes/minikube/releases/download/{{ minikube_version }}/minikube-linux-amd64"
          dest: /usr/local/bin/minikube
          mode: '0755'

      # fix: static path for a kubectl version
      - name: Install kubectl
        get_url:
          url: "https://dl.k8s.io/release/{{ kubernetes_version }}/bin/linux/amd64/kubectl"
          dest: /usr/local/bin/kubectl
          mode: '0755'

    when: skip_install | default(false) == false

  - name: Creating ssh key and storing it
    # storing creds in the {{ ansible_user }} user's home directory
    become: yes
    become_user: "{{ ansible_user }}"
    block:
    - name: Ensure the .ssh directory exists
      file:
        path: "/home/{{ ansible_user }}/.ssh"
        state: directory
        mode: '0700'
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"

    - name: Generate SSH key if it does not exist
      shell: |
        if [ ! -f "/home/{{ ansible_user }}/.ssh/id_rsa" ]; then
          ssh-keygen -t rsa -b 4096 -f "/home/{{ ansible_user }}/.ssh/id_rsa" -N "" -C "ansible-generated-key";
        fi
      args:
        creates: "/home/{{ ansible_user }}/.ssh/id_rsa"

    - name: Read the private key
      slurp:
        src: "/home/{{ ansible_user }}/.ssh/id_rsa"
      register: ssh_key_private

    - name: Read the public key content
      slurp:
        src: "/home/{{ ansible_user }}/.ssh/id_rsa.pub"
      register: ssh_key_content

    - name: Set the public key as a fact
      set_fact:
        ssh_public_key: "{{ ssh_key_content['content'] | b64decode }}"

    - name: Set the private key as a fact
      set_fact:
        ssh_private_key: "{{ ssh_key_private['content'] | b64decode }}"

    - name: Add SSH key to the node to use it as a assethost
      authorized_key:
        user: "{{ ansible_user }}"
        state: present
        key: "{{ ssh_public_key }}"

    when: ((skip_minikube | default(false) == false) or (skip_download | default(false) == false) or (skip_wire_assets | default(false) == false) or (skip_setup_offline_seed | default(false) == false))

  - name: start k8s(minikube) cluster 
    become: yes
    become_user: "{{ ansible_user }}"
    block:
    - name: Check if Minikube is running
      shell: minikube status
      register: minikube_status
      failed_when: false
      changed_when: false

    # fix the version of minikube and kicbase images
    - name: Start Minikube with specified configurations
      shell: |
        minikube start \
          --nodes={{ minikube_nodes }} \
          --cpus={{ minikube_cpus }} \
          --memory={{ minikube_memory }} \
          --disk-size={{ minikube_disk_size }} \
          --kubernetes-version="{{ kubernetes_version }}" \
          --container-runtime="{{ container_runtime }}" \
          --driver=docker \
          --extra-config=kubeadm.pod-network-cidr={{ pod_network_cidr }} \
          --network={{ minikube_network_name }} \
          --subnet={{ minikube_node_subnet }} \
          --wait=all
      when: "'Running' not in minikube_status.stdout"

    - name: Get list of running Minikube nodes
      shell: minikube node list | awk '{print $1}'
      register: minikube_nodes_raw

    - name: Add SSH key to all Minikube nodes
      shell: |
        minikube ssh --native-ssh=false -n {{ item }} -- "mkdir -p ~/.ssh && echo '{{ ssh_public_key }}' >> ~/.ssh/authorized_keys && chmod 600 ~/.ssh/authorized_keys"
      args:
        executable: /bin/bash
      with_items: "{{  minikube_nodes_raw.stdout_lines }}"
      async: 30
      poll: 5

    when: skip_minikube | default(false) == false

  - name: Generate hosts.ini with dynamic IPs
    become: yes
    become_user: "{{ ansible_user }}"
    block:

    - name: Display running containers
      shell: docker ps
      register: docker_ps_output

    - name: Print Docker container information
      debug:
        var: docker_ps_output.stdout

    - name: Extract IPs of Minikube nodes
      shell: |
        kubectl get nodes -o json | jq -r '.items[].status.addresses[] | select(.type=="InternalIP").address'
      register: kube_ips

    - name: Store Minikube node IPs as variable
      set_fact:
        kubernetes_node_ips: "{{ kube_ips.stdout_lines }}"

    - name: Display Kubernetes node IPs
      debug:
        msg: "Kubernetes Node IPs: {{ kubernetes_node_ips }}"

    - name: Extract IP of "{{ minikube_network_name }}" interface on host machine
      shell: |
        docker network inspect "{{ minikube_network_name }}" | jq -r '.[0].IPAM.Config[0].Gateway'
      register: host_ip

    - name: Create dictionary for Kubernetes nodes and container IPs
      set_fact:
        host_ips:
          kubenode1: "{{ kubernetes_node_ips[0] }}"
          kubenode2: "{{ kubernetes_node_ips[1] }}"
          kubenode3: "{{ kubernetes_node_ips[2] }}"
          # ip address of the minikube network interface on the machine
          assethost: "{{ host_ip.stdout }}"

    - name: Generate hosts.ini content
      set_fact:
        hosts_ini_content: |
          [all]
          kubenode1 ansible_host={{ host_ips.kubenode1 }} ansible_user=docker
          kubenode2 ansible_host={{ host_ips.kubenode2 }} ansible_user=docker
          kubenode3 ansible_host={{ host_ips.kubenode3 }} ansible_user=docker
          assethost ansible_host={{ host_ips.assethost }} ansible_user="{{ ansible_user }}"

          [all:vars]
          ansible_ssh_common_args = '-o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no'

          [kube-master]
          kubenode1
          kubenode2
          kubenode3

          [etcd]
          kubenode1 etcd_member_name=etcd1
          kubenode2 etcd_member_name=etcd2
          kubenode3 etcd_member_name=etcd3

          [kube-node]
          kubenode1
          kubenode2
          kubenode3

          [k8s-cluster:children]
          kube-master
          kube-node

    when: ((skip_minikube | default(false) == false) or (skip_download | default(false) == false) or (skip_wire_assets | default(false) == false) or (skip_setup_offline_seed | default(false) == false))

  - name: Download wire artifact
    become: yes
    become_user: "{{ ansible_user }}"
    block:
      - name: create wire-server-deploy directory for {{ ansible_user }} user
        file:
          path: /home/{{ ansible_user }}/wire-server-deploy
          state: directory
          owner: "{{ ansible_user }}"
          group: "{{ ansible_user }}"
          mode: 0775

      - name: check if wire-server-deploy-static-demo-{{ artifact_hash }}.tgz exists
        stat:
          path: /home/{{ ansible_user }}/wire-server-deploy-static-demo-{{ artifact_hash }}.tgz
          get_checksum: False
        register: artifact_archive_file_check

      - name: download wire-server-deploy archive
        shell:
          cmd: curl -fsSLo /home/{{ ansible_user }}/wire-server-deploy-static-demo-{{ artifact_hash }}.tgz https://s3-eu-west-1.amazonaws.com/public.wire.com/artifacts/wire-server-deploy-static-demo-{{ artifact_hash }}.tgz
          creates: /home/{{ ansible_user }}/wire-server-deploy-static-demo-{{ artifact_hash }}.tgz
        when: not artifact_archive_file_check.stat.exists
        register: artifact_archive
        async: 1200
        poll: 0

      - name: Waiting on async task artifact_archive
        async_status:
          jid: "{{ artifact_archive.ansible_job_id }}"
        register: res
        until: res.finished
        retries: 20
        delay: 60
        when: not artifact_archive_file_check.stat.exists

      - name: check if wire-server-deploy folder contents exist
        stat:
          path: /home/{{ ansible_user }}/wire-server-deploy/containers-helm.tar
          get_checksum: False
        register: artifact_folder_content_check

      - name: unpack wire-server-deploy archive, will take a few mins
        unarchive:
          src: /home/{{ ansible_user }}/wire-server-deploy-static-demo-{{ artifact_hash }}.tgz
          dest: /home/{{ ansible_user }}/wire-server-deploy
          remote_src: yes
        when: not artifact_folder_content_check.stat.exists

      - name: set permissions inside wire-server-deploy via shell command (fails when using ansible directive)
        shell:
          cmd: sudo chmod -R 0775 /home/{{ ansible_user }}/wire-server-deploy; sudo chown -R {{ ansible_user }}:{{ ansible_user }} /home/{{ ansible_user }}

    when: skip_download | default(false) == false

  - name: Write updated hosts.ini to file
    copy:
      dest:  /home/{{ ansible_user }}/wire-server-deploy/ansible/inventory/offline/hosts.ini
      content: "{{ hosts_ini_content }}"
    when: ((skip_minikube | default(false) == false) or (skip_download | default(false) == false) or (skip_wire_assets | default(false) == false) or (skip_setup_offline_seed | default(false) == false))

  - name: Configure iptables rules
    become: yes
    block:
    - name: Get the default interface for the default route
      shell: ip route | awk '/default/ {print $5}' | head -n 1
      register: default_interface
      changed_when: false

    - name: Get the IP address of the default interface
      shell: ip -4 addr show dev {{ default_interface.stdout }} | awk '/inet / {print $2}' | cut -d/ -f1
      register: default_interface_ip
      changed_when: false

    - name: Get the IP address of the k8s_ingress_controller node
      shell: |
        kubectl get node {{ k8s_ingress_controller_node }} -o json | jq -r '.status.addresses[] | select(.type=="InternalIP").address'
      register: k8s_ingress_controller_ip
      become: yes
      become_user: "{{ ansible_user }}"
      changed_when: false

    - name: Configure DNAT rules to send http/https traffic to the k8s ingress controller
      iptables:
        table: nat
        chain: PREROUTING
        protocol: "{{ item.protocol }}"
        jump: DNAT
        in_interface: "{{ default_interface.stdout }}"
        destination: "{{ default_interface_ip.stdout }}"
        destination_port: "{{ item.port }}"
        to_destination: "{{ k8s_ingress_controller_ip.stdout }}:{{ item.to_port }}"
        state: present
        action: insert
      loop: "{{ http_dnat_rules }}"
      loop_control:
        label: "Setting DNAT rule for port {{ item.port }} -> {{ k8s_ingress_controller_ip.stdout | default('undefined') }}:{{ item.to_port }}"

    - name: Get the {{ minikube_network_name }} Docker network ID
      shell: |
        docker network inspect {{ minikube_network_name }} | jq -r '.[0].Id'
      register: docker_network_id
      changed_when: false

    - name: Get all interfaces with bridge interfaces
      shell: ip -o addr show | awk '{print $2}' | grep -i 'br-'
      register: bridge_interfaces
      changed_when: false

    - name: Find the matching bridge interface for {{ minikube_network_name }} Docker network
      shell: |
        for iface in {{ bridge_interfaces.stdout_lines | join(' ') }}; do
          iface_id=$(echo "$iface" | cut -d '-' -f2)
          if echo "{{ docker_network_id.stdout }}" | grep -q "$iface_id"; then
            echo "$iface"
            break
          fi
        done
      register: matching_bridge_interface
      changed_when: false
    
    - name: Ensure FORWARD rule for traffic from main interface to ingress controller
      iptables:
        table: filter
        chain: FORWARD
        in_interface: "{{ default_interface.stdout }}"
        out_interface: "{{ matching_bridge_interface.stdout }}"
        jump: ACCEPT
        state: present
        action: insert

    - name: Ensure FORWARD rule for traffic from ingress controller to main interface
      iptables:
        table: filter
        chain: FORWARD
        in_interface: "{{ matching_bridge_interface.stdout }}"
        out_interface: "{{ default_interface.stdout }}"
        jump: ACCEPT
        state: present
        action: insert

    - name: Get the IP address of the coturn node
      shell: |
        kubectl get node {{ coturn_k8s_node }} -o json | jq -r '.status.addresses[] | select(.type=="InternalIP").address'
      register: coturn_k8s_node_ip
      become: yes
      become_user: "{{ ansible_user }}"
      changed_when: false

    - name: Configure DNAT rule to send UDP traffic for coturn to coturn server on k8s node
      iptables:
        table: nat
        chain: PREROUTING
        protocol: udp
        jump: DNAT
        destination: "{{ default_interface_ip.stdout }}"
        destination_ports: "49152:65535"
        in_interface: "{{ default_interface.stdout }}"
        to_destination: "{{ coturn_k8s_node_ip.stdout }}"
        state: present
        action: insert

    - name: Configure DNAT rules to reach turn servers running on k8s node
      iptables:
        table: nat
        chain: PREROUTING
        protocol: "{{ item.protocol }}"
        jump: DNAT
        in_interface: "{{ default_interface.stdout }}"
        destination: "{{ default_interface_ip.stdout }}"
        destination_port: "{{ item.port }}"
        to_destination: "{{ coturn_k8s_node_ip.stdout }}:{{ item.to_port }}"
        state: present
        action: insert
      loop: "{{ turn_dnat_rules }}"
      loop_control:
        label: "Setting DNAT rule for port {{ item.port }} -> {{ coturn_k8s_node_ip.stdout | default('undefined') }}:{{ item.to_port }}"

    - name: Ensure /etc/iptables directory exists
      ansible.builtin.file:
        path: /etc/iptables
        state: directory
        owner: root
        group: root
        mode: '0755'

    - name: Save iptables rules
      shell: iptables-save -f /etc/iptables/rules.v4 

    when: skip_minikube | default(false) == false

  - name: Setup ssh proxy access to k8s-cluster nodes
    become: no
    block:
    - name: Create a temporary directory
      tempfile:
        state: directory
        suffix: _ssh_keys
      register: temp_dir
      delegate_to: localhost

    - name: Write the private key to a file
      copy:
        content: "{{ ssh_private_key }}"
        dest: "{{ temp_dir.path }}/id_rsa"
        mode: '0600'
      delegate_to: localhost

    - name: Add containers to inventory
      become: yes
      become_user: "{{ ansible_user }}"
      add_host:
        name: "{{ item }}"
        groups: k8s-cluster
        ansible_user: docker
        ansible_ssh_common_args: >-
          -o ProxyCommand="ssh -W %h:%p -q {{ ansible_user }}@{{ ansible_host }}"
          -o StrictHostKeyChecking=no
          -i {{ temp_dir.path }}/id_rsa
      loop: "{{ kubernetes_node_ips }}"

    - name: Define inventory for the assethost to match the hostname in setup-offline-sources.yml
      become: yes
      become_user: "{{ ansible_user }}"
      add_host:
        name: "{{ host_ips.assethost }}"
        group: assethost
        ansible_user: "{{ ansible_user }}"
        ansible_ssh_common_args: >-
          -o ProxyCommand="ssh -W %h:%p -q {{ ansible_user }}@{{ ansible_host }}"
          -o StrictHostKeyChecking=no

    - name: Set assethost_host variable
      set_fact:
        assethost_host: "{{ host_ips.assethost }}"
      delegate_to: localhost
      delegate_facts: true

    - name: Set original_node variable
      set_fact:
        original_node: "{{ ansible_host }}"
      delegate_to: localhost
      delegate_facts: true

    when: ((skip_wire_assets | default(false) == false) or (skip_setup_offline_seed | default(false) == false))

  - name: Setup offline sources on asset host
    become: yes
    block:
    - file:
        path: /opt/assets
        state: directory

    - name: Copy helm containers
      unarchive:
        src: "/home/{{ ansible_user }}/wire-server-deploy/containers-helm.tar"
        dest: /opt/assets
        remote_src: yes
    - name: Create serve-assets systemd service
      copy:
        src: ../files/serve-assets.service
        dest: /etc/systemd/system/serve-assets.service
    - name: Setup serve-assets systemd service
      systemd:
        name: serve-assets
        state: restarted
        enabled: yes
        daemon-reload: yes
    when: skip_wire_assets | default(false) == false

#- name: Setup offline sources on asset host
#  import_playbook: ../setup-offline-sources.yml
#  vars:
#    src_path: "/home/{{ ansible_user }}/wire-server-deploy"
#    remote_src: yes
#    assethost_host: "{{ hostvars['localhost']['assethost_host'] }}:8080"
#    skip_setup_binary_system_containers: true
#  when: skip_wire_assets | default(false) == false

#- name: Fix gpg keys issue with kicbase container nodes
#  import_playbook: ./update-kicbase-gpg-keys.yml
#  when: skip_setup_offline_seed | default(false) == false
    
- name: Seed the containers in k8s-cluster nodes
  import_playbook: ../seed-offline-containerd.yml
  vars:
    assethost_host: "{{ hostvars['localhost']['assethost_host'] }}:8080"
    docker_permission_fix: true
    skip_seed_system_containers: true
  when: skip_setup_offline_seed | default(false) == false

- name: Continue operations without the ssh proxy
  hosts: deploy_node
  gather_facts: yes
  become_user: "{{ ansible_user }}"
  become: yes
  tasks:

  - name: Creating wire secrets
    become: yes
    block:
    - name: Generate random strings for zrest, minio_access_key, and minio_secret_key
      shell: "tr -dc A-Za-z0-9 </dev/urandom | head -c {{ item.length }}"
      register: random_strings
      changed_when: false
      with_items:
        - { name: 'zrest', length: 64 }
        - { name: 'minio_access_key', length: 20 }
        - { name: 'minio_secret_key', length: 42 }

    - name: Set generated random strings as facts
      set_fact:
        "{{ item.item.name }}": "{{ item.stdout }}"
      with_items: "{{ random_strings.results }}"

    - name: find zauth container image name
      shell: ls /home/{{ ansible_user }}/wire-server-deploy/containers-adminhost/quay.io_wire_zauth_*.tar
      register: zauth_docker_image

    - name: Load ZAUTH Docker image
      shell: |
        docker load -i "{{ zauth_docker_image.stdout }}" | awk '{print $3}'
      register: zauth_container

    - name: Generate zauth keypair
      shell: docker run "{{ zauth_container.stdout }}" -m gen-keypair -i 1
      register: zauth_output
      changed_when: false

    - name: Extract zauth keys
      set_fact:
        zauth_public: "{{ zauth_output.stdout_lines[0].split()[1] }}"
        zauth_private: "{{ zauth_output.stdout_lines[1].split()[1] }}"

    - name: Created following secrets
      debug:
        msg:
          - "zrest: {{ zrest }}"
          - "minio_access_key: {{ minio_access_key }}"
          - "minio_secret_key: {{ minio_secret_key }}"
          - "zauth_public: {{ zauth_public }}"
          - "zauth_private: {{ zauth_private }}"

    - name: Update values in secrets.yaml using Python yq
      shell: |
        yq -yi '.brig.secrets.turn.secret = "{{ zrest }}"' {{ secrets_yaml_path }}
        yq -yi '.cargohold.secrets.awsKeyId = "{{ minio_access_key }}"' {{ secrets_yaml_path }}
        yq -yi '.cargohold.secrets.awsSecretKey = "{{ minio_secret_key }}"' {{ secrets_yaml_path }}
        yq -yi '.brig.secrets.zAuth.publicKeys = "{{ zauth_public }}"' {{ secrets_yaml_path }}
        yq -yi '.brig.secrets.zAuth.privateKeys = "{{ zauth_private }}"' {{ secrets_yaml_path }}
        yq -yi '.nginz.secrets.zAuth.publicKeys = "{{ zauth_public }}"' {{ secrets_yaml_path }}
      args:
        executable: /bin/bash
      vars:
        secrets_yaml_path: "/home/{{ ansible_user }}/wire-server-deploy/values/wire-server/demo-secrets.example.yaml"

    when: ((skip_wire_secrets | default(false) == false) and (skip_helm_install | default(false) == false))

  - name: Installing helm charts
    block:

    - name: Replace TARGET_SYSTEM example.com with target_domain in offline_deploy_k8s
      lineinfile:
        path: /home/{{ ansible_user }}/wire-server-deploy/bin/wiab-demo/offline_deploy_k8s.sh
        regexp: '^TARGET_SYSTEM="example\.com"'
        line: 'TARGET_SYSTEM="{{ target_domain }}"'
        backrefs: yes

    - name: Replace CERT_MASTER_EMAIL example.com with target_domain in offline_deploy_k8s
      lineinfile:
        path: /home/{{ ansible_user }}/wire-server-deploy/bin/wiab-demo/offline_deploy_k8s.sh
        regexp: '^CERT_MASTER_EMAIL="certmaster@example\.com"'
        line: 'CERT_MASTER_EMAIL="certmaster@{{ target_domain }}"'
        backrefs: yes

    - name: Load WSD Docker image
      shell: |
        docker load -i "/home/{{ ansible_user }}/wire-server-deploy/containers-adminhost/container-wire-server-deploy.tgz" | awk '{print $3}'
      register: wsd_container

    - name: Process charts for demo environment
      shell: |
        {{ docker_cmd_base }} bash -c "source /wire-server-deploy/bin/wiab-demo/offline_deploy_k8s.sh && process_charts demo"
      args:
        executable: /bin/bash
    
    - name: Process values
      shell: |
        {{ docker_cmd_base }} bash -c "source /wire-server-deploy/bin/wiab-demo/offline_deploy_k8s.sh && process_values"
      args:
        executable: /bin/bash
    
    - name: Deploy cert manager
      shell: |
        {{ docker_cmd_base }} bash -c "source /wire-server-deploy/bin/wiab-demo/offline_deploy_k8s.sh && deploy_cert_manager"
      args:
        executable: /bin/bash
    
    - name: Deploy chart
      shell: |
        {{ docker_cmd_base }} bash -c "source /wire-server-deploy/bin/wiab-demo/offline_deploy_k8s.sh && deploy_charts {{ item }}"
      args:
        executable: /bin/bash
      loop: "{{ charts_to_deploy }}"

    - name: Deploy calling stack
      shell: |
        {{ docker_cmd_base }} bash -c "source /wire-server-deploy/bin/wiab-demo/offline_deploy_k8s.sh && deploy_calling_services"
      args:
        executable: /bin/bash

    when: skip_helm_install | default(false) == false

